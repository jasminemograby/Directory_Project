# F005: Complete Test Flow - Step by Step

## âœ… Migration Complete
- [x] UNIQUE constraint added
- [x] updated_at column added

## ×©×œ×‘ 1: × ×§×” × ×ª×•× ×™× ×§×™×™××™× (××•×¤×¦×™×•× ×œ×™)

×× ×™×© × ×ª×•× ×™× ×™×©× ×™×, × ×§×” ××•×ª×:

```sql
-- ××—×§ × ×ª×•× ×™× ×™×©× ×™× (×× ×™×©)
DELETE FROM oauth_tokens WHERE employee_id = 'YOUR_EMPLOYEE_ID';
DELETE FROM external_data_raw WHERE employee_id = 'YOUR_EMPLOYEE_ID';
DELETE FROM external_data_processed WHERE employee_id = 'YOUR_EMPLOYEE_ID';
DELETE FROM projects WHERE employee_id = 'YOUR_EMPLOYEE_ID' AND source = 'gemini_ai';
```

## ×©×œ×‘ 2: ×‘×“×•×§ ×©×”×˜×‘×œ××•×ª ×¨×™×§×•×ª

```sql
-- ×‘×“×•×§ ×©××™×Ÿ tokens
SELECT COUNT(*) as token_count FROM oauth_tokens WHERE employee_id = 'YOUR_EMPLOYEE_ID';

-- ×‘×“×•×§ ×©××™×Ÿ raw data
SELECT COUNT(*) as raw_data_count FROM external_data_raw WHERE employee_id = 'YOUR_EMPLOYEE_ID';

-- ×‘×“×•×§ ×©××™×Ÿ processed data
SELECT COUNT(*) as processed_count FROM external_data_processed WHERE employee_id = 'YOUR_EMPLOYEE_ID';
```

**Expected**: ×›×œ ×”-counts = 0

## ×©×œ×‘ 3: Connect LinkedIn

1. **×¤×ª×— ×¤×¨×•×¤×™×œ**: `https://directory-project-bice.vercel.app/profile`
2. **×•×“× ×©-localStorage ××›×™×œ employee ID**:
   ```javascript
   localStorage.getItem('currentEmployeeId')
   ```
3. **×œ×—×¥ "Connect" ×œ-LinkedIn**
4. **××©×¨ ×‘-LinkedIn** (×ª×•×¢×‘×¨×™ ×œ-LinkedIn, ×ª××©×¨×™, ×ª×—×–×¨×™)
5. **×”×“×£ ×××•×¨ ×œ×”×¦×™×’**: "LinkedIn connected successfully!"

### ×‘×“×•×§ ×‘-Database:

```sql
-- ×‘×“×•×§ ×©×”-token × ×©××¨
SELECT 
  id,
  employee_id,
  provider,
  created_at,
  expires_at
FROM oauth_tokens 
WHERE employee_id = 'YOUR_EMPLOYEE_ID' 
  AND provider = 'linkedin';
```

**Expected**: ×©×•×¨×” ××—×ª ×¢× token

## ×©×œ×‘ 4: Connect GitHub

1. **×¢×œ ××•×ª×• ×“×£ ×¤×¨×•×¤×™×œ**
2. **×œ×—×¥ "Connect" ×œ-GitHub**
3. **××©×¨ ×‘-GitHub** (×ª×•×¢×‘×¨×™ ×œ-GitHub, ×ª××©×¨×™, ×ª×—×–×¨×™)
4. **×”×“×£ ×××•×¨ ×œ×”×¦×™×’**: "GitHub connected successfully!"

### ×‘×“×•×§ ×‘-Database:

```sql
-- ×‘×“×•×§ ×©×”-token × ×©××¨
SELECT 
  id,
  employee_id,
  provider,
  created_at,
  expires_at
FROM oauth_tokens 
WHERE employee_id = 'YOUR_EMPLOYEE_ID' 
  AND provider = 'github';
```

**Expected**: ×©×•×¨×” ××—×ª ×¢× token

## ×©×œ×‘ 5: Collect All Data

### ××•×¤×¦×™×” 1: ××•×˜×•××˜×™
×× ×”-frontend ×§×•×¨× ××•×˜×•××˜×™×ª ×œ-`collectAllExternalData` ××—×¨×™ ×—×™×‘×•×¨, ×–×” ×§×•×¨×” ××•×˜×•××˜×™×ª.

### ××•×¤×¦×™×” 2: ×™×“× ×™
×× ×™×© ×›×¤×ª×•×¨ "Collect All Data", ×œ×—×¦×™ ×¢×œ×™×•.

### ××•×¤×¦×™×” 3: ×“×¨×š Console
×¤×ª×—×™ Console (F12) ×•×”×¨×¦×™:

```javascript
const employeeId = localStorage.getItem('currentEmployeeId');
fetch(`https://directoryproject-production.up.railway.app/api/external/collect/${employeeId}`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' }
})
.then(r => r.json())
.then(data => {
  console.log('âœ… Collect Result:', data);
  setTimeout(() => window.location.reload(), 3000);
})
.catch(err => console.error('âŒ Error:', err));
```

## ×©×œ×‘ 6: ×‘×“×•×§ Raw Data

```sql
-- ×‘×“×•×§ ×©×”-raw data × ×©××¨
SELECT 
  id,
  employee_id,
  provider,
  processed,
  fetched_at,
  LENGTH(data::text) as data_size
FROM external_data_raw 
WHERE employee_id = 'YOUR_EMPLOYEE_ID'
ORDER BY fetched_at DESC;
```

**Expected**: 
- 2 ×©×•×¨×•×ª (LinkedIn + GitHub)
- `processed = false`
- `data_size > 0`

## ×©×œ×‘ 7: ×‘×“×•×§ Processed Data (Gemini)

**×”××ª×Ÿ 10-30 ×©× ×™×•×ª** (Gemini ×¦×¨×™×š ×œ×¢×‘×“)

```sql
-- ×‘×“×•×§ ×©×”-processed data × ×©××¨
SELECT 
  id,
  employee_id,
  bio,
  processed_at
FROM external_data_processed 
WHERE employee_id = 'YOUR_EMPLOYEE_ID';
```

**Expected**: ×©×•×¨×” ××—×ª ×¢× `bio` (×œ× null)

```sql
-- ×‘×“×•×§ ×©×”-projects × ×©××¨×•
SELECT 
  id,
  employee_id,
  title,
  summary,
  source,
  created_at
FROM projects 
WHERE employee_id = 'YOUR_EMPLOYEE_ID' 
  AND source = 'gemini_ai'
ORDER BY created_at DESC;
```

**Expected**: ××¡×¤×¨ ×©×•×¨×•×ª ×¢× projects

```sql
-- ×‘×“×•×§ ×©×”-raw data ××¡×•××Ÿ ×›-processed
SELECT 
  provider,
  processed,
  fetched_at
FROM external_data_raw 
WHERE employee_id = 'YOUR_EMPLOYEE_ID';
```

**Expected**: ×›×œ ×”×©×•×¨×•×ª ×¢× `processed = true`

## ×©×œ×‘ 8: ×‘×“×•×§ Frontend Display

1. **×¨×¢× ×Ÿ ××ª ×”×¤×¨×•×¤×™×œ**
2. **×××•×¨ ×œ×¨××•×ª**:
   - âœ… **Professional Bio** (×˜×§×¡×˜ ×©× ×•×¦×¨ ×¢×œ ×™×“×™ Gemini)
   - âœ… **Projects** (×¨×©×™××ª ×¤×¨×•×™×§×˜×™×)
   - âœ… **Skills** (×× Skills Engine ××•×›×Ÿ)

3. **×œ× ×××•×¨ ×œ×¨××•×ª**:
   - âŒ Raw JSON data
   - âŒ Unprocessed data
   - âŒ OAuth tokens

## ×©×œ×‘ 9: ×‘×“×•×§ Railway Logs

1. ×œ×š ×œ-Railway Dashboard
2. ×‘×—×¨ backend service
3. ×œ×š ×œ-**Deployments** â†’ Latest â†’ **View Logs**
4. ×—×¤×©:
   - `[LinkedIn Callback] Processing OAuth for employee: ...`
   - `[LinkedIn] âœ… Token stored successfully`
   - `[LinkedIn] âœ… Raw data stored`
   - `[Enrichment] Starting profile enrichment`
   - `[Gemini] Bio generation complete`
   - `[Enrichment] Bio stored in external_data_processed`
   - `[Enrichment] X projects stored`

## âœ… Success Criteria

- [ ] OAuth tokens × ×©××¨×™× ×‘-database (2 tokens: LinkedIn + GitHub)
- [ ] Raw data × ×©××¨ ×‘-external_data_raw (2 records, processed=false)
- [ ] Processed data × ×©××¨ ×‘-external_data_processed (bio exists)
- [ ] Projects × ×©××¨×™× ×‘-projects table (source='gemini_ai')
- [ ] Raw data ××¡×•××Ÿ ×›-processed=true
- [ ] Frontend ××¦×™×’ bio + projects (×œ× raw data)
- [ ] Railway logs ××¨××™× ××ª ×›×œ ×”×©×œ×‘×™×

## ğŸ¯ ×× ×”×›×œ ×¢×•×‘×“

**F005 ××•×›×Ÿ ×œ-production!** ğŸ‰

×”××¢×¨×›×ª ×¢×›×©×™×•:
- âœ… ×¢×•×‘×“×ª per-user
- âœ… ×©×•××¨×ª tokens per-user
- âœ… ××¢×‘×“×ª × ×ª×•× ×™× per-user
- âœ… ××¦×™×’×” ×¨×§ processed data
- âœ… ××•×›× ×” ×œ××©×ª××©×™× ×××™×ª×™×™×

